// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/assistant/embedded/v1alpha2/embedded_assistant.proto

package com.google.assistant.embedded.v1alpha2;

/**
 * <pre>
 * The dialog state resulting from the user's query. Multiple of these messages
 * may be received.
 * </pre>
 *
 * Protobuf type {@code google.assistant.embedded.v1alpha2.DialogStateOut}
 */
public  final class DialogStateOut extends
    com.google.protobuf.GeneratedMessageLite<
        DialogStateOut, DialogStateOut.Builder> implements
    // @@protoc_insertion_point(message_implements:google.assistant.embedded.v1alpha2.DialogStateOut)
    DialogStateOutOrBuilder {
  private DialogStateOut() {
    supplementalDisplayText_ = "";
    conversationState_ = com.google.protobuf.ByteString.EMPTY;
  }
  /**
   * <pre>
   * Possible states of the microphone after a `Assist` RPC completes.
   * </pre>
   *
   * Protobuf enum {@code google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode}
   */
  public enum MicrophoneMode
      implements com.google.protobuf.Internal.EnumLite {
    /**
     * <pre>
     * No mode specified.
     * </pre>
     *
     * <code>MICROPHONE_MODE_UNSPECIFIED = 0;</code>
     */
    MICROPHONE_MODE_UNSPECIFIED(0),
    /**
     * <pre>
     * The service is not expecting a follow-on question from the user.
     * The microphone should remain off until the user re-activates it.
     * </pre>
     *
     * <code>CLOSE_MICROPHONE = 1;</code>
     */
    CLOSE_MICROPHONE(1),
    /**
     * <pre>
     * The service is expecting a follow-on question from the user. The
     * microphone should be re-opened when the `AudioOut` playback completes
     * (by starting a new `Assist` RPC call to send the new audio).
     * </pre>
     *
     * <code>DIALOG_FOLLOW_ON = 2;</code>
     */
    DIALOG_FOLLOW_ON(2),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * No mode specified.
     * </pre>
     *
     * <code>MICROPHONE_MODE_UNSPECIFIED = 0;</code>
     */
    public static final int MICROPHONE_MODE_UNSPECIFIED_VALUE = 0;
    /**
     * <pre>
     * The service is not expecting a follow-on question from the user.
     * The microphone should remain off until the user re-activates it.
     * </pre>
     *
     * <code>CLOSE_MICROPHONE = 1;</code>
     */
    public static final int CLOSE_MICROPHONE_VALUE = 1;
    /**
     * <pre>
     * The service is expecting a follow-on question from the user. The
     * microphone should be re-opened when the `AudioOut` playback completes
     * (by starting a new `Assist` RPC call to send the new audio).
     * </pre>
     *
     * <code>DIALOG_FOLLOW_ON = 2;</code>
     */
    public static final int DIALOG_FOLLOW_ON_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MicrophoneMode valueOf(int value) {
      return forNumber(value);
    }

    public static MicrophoneMode forNumber(int value) {
      switch (value) {
        case 0: return MICROPHONE_MODE_UNSPECIFIED;
        case 1: return CLOSE_MICROPHONE;
        case 2: return DIALOG_FOLLOW_ON;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<MicrophoneMode>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        MicrophoneMode> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<MicrophoneMode>() {
            public MicrophoneMode findValueByNumber(int number) {
              return MicrophoneMode.forNumber(number);
            }
          };

    private final int value;

    private MicrophoneMode(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode)
  }

  public static final int SUPPLEMENTAL_DISPLAY_TEXT_FIELD_NUMBER = 1;
  private java.lang.String supplementalDisplayText_;
  /**
   * <pre>
   * *Output-only* Supplemental display text from the Assistant. This could be
   * the same as the speech spoken in `AssistResponse.audio_out` or it could
   * be some additional information which aids the user's understanding.
   * </pre>
   *
   * <code>optional string supplemental_display_text = 1;</code>
   */
  public java.lang.String getSupplementalDisplayText() {
    return supplementalDisplayText_;
  }
  /**
   * <pre>
   * *Output-only* Supplemental display text from the Assistant. This could be
   * the same as the speech spoken in `AssistResponse.audio_out` or it could
   * be some additional information which aids the user's understanding.
   * </pre>
   *
   * <code>optional string supplemental_display_text = 1;</code>
   */
  public com.google.protobuf.ByteString
      getSupplementalDisplayTextBytes() {
    return com.google.protobuf.ByteString.copyFromUtf8(supplementalDisplayText_);
  }
  /**
   * <pre>
   * *Output-only* Supplemental display text from the Assistant. This could be
   * the same as the speech spoken in `AssistResponse.audio_out` or it could
   * be some additional information which aids the user's understanding.
   * </pre>
   *
   * <code>optional string supplemental_display_text = 1;</code>
   */
  private void setSupplementalDisplayText(
      java.lang.String value) {
    if (value == null) {
    throw new NullPointerException();
  }
  
    supplementalDisplayText_ = value;
  }
  /**
   * <pre>
   * *Output-only* Supplemental display text from the Assistant. This could be
   * the same as the speech spoken in `AssistResponse.audio_out` or it could
   * be some additional information which aids the user's understanding.
   * </pre>
   *
   * <code>optional string supplemental_display_text = 1;</code>
   */
  private void clearSupplementalDisplayText() {
    
    supplementalDisplayText_ = getDefaultInstance().getSupplementalDisplayText();
  }
  /**
   * <pre>
   * *Output-only* Supplemental display text from the Assistant. This could be
   * the same as the speech spoken in `AssistResponse.audio_out` or it could
   * be some additional information which aids the user's understanding.
   * </pre>
   *
   * <code>optional string supplemental_display_text = 1;</code>
   */
  private void setSupplementalDisplayTextBytes(
      com.google.protobuf.ByteString value) {
    if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
    
    supplementalDisplayText_ = value.toStringUtf8();
  }

  public static final int CONVERSATION_STATE_FIELD_NUMBER = 2;
  private com.google.protobuf.ByteString conversationState_;
  /**
   * <pre>
   * *Output-only* State information for the subsequent `Assist` RPC. This
   * value should be saved in the client and returned in the
   * [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
   * `Assist` RPC. (The client does not need to interpret or otherwise use this
   * value.) This information should be saved across device reboots. However,
   * this value should be cleared (not saved in the client) during a
   * factory-default reset.
   * </pre>
   *
   * <code>optional bytes conversation_state = 2;</code>
   */
  public com.google.protobuf.ByteString getConversationState() {
    return conversationState_;
  }
  /**
   * <pre>
   * *Output-only* State information for the subsequent `Assist` RPC. This
   * value should be saved in the client and returned in the
   * [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
   * `Assist` RPC. (The client does not need to interpret or otherwise use this
   * value.) This information should be saved across device reboots. However,
   * this value should be cleared (not saved in the client) during a
   * factory-default reset.
   * </pre>
   *
   * <code>optional bytes conversation_state = 2;</code>
   */
  private void setConversationState(com.google.protobuf.ByteString value) {
    if (value == null) {
    throw new NullPointerException();
  }
  
    conversationState_ = value;
  }
  /**
   * <pre>
   * *Output-only* State information for the subsequent `Assist` RPC. This
   * value should be saved in the client and returned in the
   * [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
   * `Assist` RPC. (The client does not need to interpret or otherwise use this
   * value.) This information should be saved across device reboots. However,
   * this value should be cleared (not saved in the client) during a
   * factory-default reset.
   * </pre>
   *
   * <code>optional bytes conversation_state = 2;</code>
   */
  private void clearConversationState() {
    
    conversationState_ = getDefaultInstance().getConversationState();
  }

  public static final int MICROPHONE_MODE_FIELD_NUMBER = 3;
  private int microphoneMode_;
  /**
   * <pre>
   * *Output-only* Specifies the mode of the microphone after this `Assist`
   * RPC is processed.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
   */
  public int getMicrophoneModeValue() {
    return microphoneMode_;
  }
  /**
   * <pre>
   * *Output-only* Specifies the mode of the microphone after this `Assist`
   * RPC is processed.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
   */
  public com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode getMicrophoneMode() {
    com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode result = com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode.forNumber(microphoneMode_);
    return result == null ? com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode.UNRECOGNIZED : result;
  }
  /**
   * <pre>
   * *Output-only* Specifies the mode of the microphone after this `Assist`
   * RPC is processed.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
   */
  private void setMicrophoneModeValue(int value) {
      microphoneMode_ = value;
  }
  /**
   * <pre>
   * *Output-only* Specifies the mode of the microphone after this `Assist`
   * RPC is processed.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
   */
  private void setMicrophoneMode(com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode value) {
    if (value == null) {
      throw new NullPointerException();
    }
    
    microphoneMode_ = value.getNumber();
  }
  /**
   * <pre>
   * *Output-only* Specifies the mode of the microphone after this `Assist`
   * RPC is processed.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
   */
  private void clearMicrophoneMode() {
    
    microphoneMode_ = 0;
  }

  public static final int VOLUME_PERCENTAGE_FIELD_NUMBER = 4;
  private int volumePercentage_;
  /**
   * <pre>
   * *Output-only* Updated volume level. The value will be 0 or omitted
   * (indicating no change) unless a voice command such as *Increase the volume*
   * or *Set volume level 4* was recognized, in which case the value will be
   * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
   * Typically, a client should use this volume level when playing the
   * `audio_out` data, and retain this value as the current volume level and
   * supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
   * clients may also implement other ways to allow the current volume level to
   * be changed, for example, by providing a knob that the user can turn.)
   * </pre>
   *
   * <code>optional int32 volume_percentage = 4;</code>
   */
  public int getVolumePercentage() {
    return volumePercentage_;
  }
  /**
   * <pre>
   * *Output-only* Updated volume level. The value will be 0 or omitted
   * (indicating no change) unless a voice command such as *Increase the volume*
   * or *Set volume level 4* was recognized, in which case the value will be
   * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
   * Typically, a client should use this volume level when playing the
   * `audio_out` data, and retain this value as the current volume level and
   * supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
   * clients may also implement other ways to allow the current volume level to
   * be changed, for example, by providing a knob that the user can turn.)
   * </pre>
   *
   * <code>optional int32 volume_percentage = 4;</code>
   */
  private void setVolumePercentage(int value) {
    
    volumePercentage_ = value;
  }
  /**
   * <pre>
   * *Output-only* Updated volume level. The value will be 0 or omitted
   * (indicating no change) unless a voice command such as *Increase the volume*
   * or *Set volume level 4* was recognized, in which case the value will be
   * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
   * Typically, a client should use this volume level when playing the
   * `audio_out` data, and retain this value as the current volume level and
   * supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
   * clients may also implement other ways to allow the current volume level to
   * be changed, for example, by providing a knob that the user can turn.)
   * </pre>
   *
   * <code>optional int32 volume_percentage = 4;</code>
   */
  private void clearVolumePercentage() {
    
    volumePercentage_ = 0;
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (!supplementalDisplayText_.isEmpty()) {
      output.writeString(1, getSupplementalDisplayText());
    }
    if (!conversationState_.isEmpty()) {
      output.writeBytes(2, conversationState_);
    }
    if (microphoneMode_ != com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode.MICROPHONE_MODE_UNSPECIFIED.getNumber()) {
      output.writeEnum(3, microphoneMode_);
    }
    if (volumePercentage_ != 0) {
      output.writeInt32(4, volumePercentage_);
    }
  }

  public int getSerializedSize() {
    int size = memoizedSerializedSize;
    if (size != -1) return size;

    size = 0;
    if (!supplementalDisplayText_.isEmpty()) {
      size += com.google.protobuf.CodedOutputStream
        .computeStringSize(1, getSupplementalDisplayText());
    }
    if (!conversationState_.isEmpty()) {
      size += com.google.protobuf.CodedOutputStream
        .computeBytesSize(2, conversationState_);
    }
    if (microphoneMode_ != com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode.MICROPHONE_MODE_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(3, microphoneMode_);
    }
    if (volumePercentage_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(4, volumePercentage_);
    }
    memoizedSerializedSize = size;
    return size;
  }

  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.DialogStateOut parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.assistant.embedded.v1alpha2.DialogStateOut prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  /**
   * <pre>
   * The dialog state resulting from the user's query. Multiple of these messages
   * may be received.
   * </pre>
   *
   * Protobuf type {@code google.assistant.embedded.v1alpha2.DialogStateOut}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageLite.Builder<
        com.google.assistant.embedded.v1alpha2.DialogStateOut, Builder> implements
      // @@protoc_insertion_point(builder_implements:google.assistant.embedded.v1alpha2.DialogStateOut)
      com.google.assistant.embedded.v1alpha2.DialogStateOutOrBuilder {
    // Construct using com.google.assistant.embedded.v1alpha2.DialogStateOut.newBuilder()
    private Builder() {
      super(DEFAULT_INSTANCE);
    }


    /**
     * <pre>
     * *Output-only* Supplemental display text from the Assistant. This could be
     * the same as the speech spoken in `AssistResponse.audio_out` or it could
     * be some additional information which aids the user's understanding.
     * </pre>
     *
     * <code>optional string supplemental_display_text = 1;</code>
     */
    public java.lang.String getSupplementalDisplayText() {
      return instance.getSupplementalDisplayText();
    }
    /**
     * <pre>
     * *Output-only* Supplemental display text from the Assistant. This could be
     * the same as the speech spoken in `AssistResponse.audio_out` or it could
     * be some additional information which aids the user's understanding.
     * </pre>
     *
     * <code>optional string supplemental_display_text = 1;</code>
     */
    public com.google.protobuf.ByteString
        getSupplementalDisplayTextBytes() {
      return instance.getSupplementalDisplayTextBytes();
    }
    /**
     * <pre>
     * *Output-only* Supplemental display text from the Assistant. This could be
     * the same as the speech spoken in `AssistResponse.audio_out` or it could
     * be some additional information which aids the user's understanding.
     * </pre>
     *
     * <code>optional string supplemental_display_text = 1;</code>
     */
    public Builder setSupplementalDisplayText(
        java.lang.String value) {
      copyOnWrite();
      instance.setSupplementalDisplayText(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Supplemental display text from the Assistant. This could be
     * the same as the speech spoken in `AssistResponse.audio_out` or it could
     * be some additional information which aids the user's understanding.
     * </pre>
     *
     * <code>optional string supplemental_display_text = 1;</code>
     */
    public Builder clearSupplementalDisplayText() {
      copyOnWrite();
      instance.clearSupplementalDisplayText();
      return this;
    }
    /**
     * <pre>
     * *Output-only* Supplemental display text from the Assistant. This could be
     * the same as the speech spoken in `AssistResponse.audio_out` or it could
     * be some additional information which aids the user's understanding.
     * </pre>
     *
     * <code>optional string supplemental_display_text = 1;</code>
     */
    public Builder setSupplementalDisplayTextBytes(
        com.google.protobuf.ByteString value) {
      copyOnWrite();
      instance.setSupplementalDisplayTextBytes(value);
      return this;
    }

    /**
     * <pre>
     * *Output-only* State information for the subsequent `Assist` RPC. This
     * value should be saved in the client and returned in the
     * [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
     * `Assist` RPC. (The client does not need to interpret or otherwise use this
     * value.) This information should be saved across device reboots. However,
     * this value should be cleared (not saved in the client) during a
     * factory-default reset.
     * </pre>
     *
     * <code>optional bytes conversation_state = 2;</code>
     */
    public com.google.protobuf.ByteString getConversationState() {
      return instance.getConversationState();
    }
    /**
     * <pre>
     * *Output-only* State information for the subsequent `Assist` RPC. This
     * value should be saved in the client and returned in the
     * [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
     * `Assist` RPC. (The client does not need to interpret or otherwise use this
     * value.) This information should be saved across device reboots. However,
     * this value should be cleared (not saved in the client) during a
     * factory-default reset.
     * </pre>
     *
     * <code>optional bytes conversation_state = 2;</code>
     */
    public Builder setConversationState(com.google.protobuf.ByteString value) {
      copyOnWrite();
      instance.setConversationState(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* State information for the subsequent `Assist` RPC. This
     * value should be saved in the client and returned in the
     * [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
     * `Assist` RPC. (The client does not need to interpret or otherwise use this
     * value.) This information should be saved across device reboots. However,
     * this value should be cleared (not saved in the client) during a
     * factory-default reset.
     * </pre>
     *
     * <code>optional bytes conversation_state = 2;</code>
     */
    public Builder clearConversationState() {
      copyOnWrite();
      instance.clearConversationState();
      return this;
    }

    /**
     * <pre>
     * *Output-only* Specifies the mode of the microphone after this `Assist`
     * RPC is processed.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
     */
    public int getMicrophoneModeValue() {
      return instance.getMicrophoneModeValue();
    }
    /**
     * <pre>
     * *Output-only* Specifies the mode of the microphone after this `Assist`
     * RPC is processed.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
     */
    public Builder setMicrophoneModeValue(int value) {
      copyOnWrite();
      instance.setMicrophoneModeValue(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Specifies the mode of the microphone after this `Assist`
     * RPC is processed.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
     */
    public com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode getMicrophoneMode() {
      return instance.getMicrophoneMode();
    }
    /**
     * <pre>
     * *Output-only* Specifies the mode of the microphone after this `Assist`
     * RPC is processed.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
     */
    public Builder setMicrophoneMode(com.google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode value) {
      copyOnWrite();
      instance.setMicrophoneMode(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Specifies the mode of the microphone after this `Assist`
     * RPC is processed.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut.MicrophoneMode microphone_mode = 3;</code>
     */
    public Builder clearMicrophoneMode() {
      copyOnWrite();
      instance.clearMicrophoneMode();
      return this;
    }

    /**
     * <pre>
     * *Output-only* Updated volume level. The value will be 0 or omitted
     * (indicating no change) unless a voice command such as *Increase the volume*
     * or *Set volume level 4* was recognized, in which case the value will be
     * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
     * Typically, a client should use this volume level when playing the
     * `audio_out` data, and retain this value as the current volume level and
     * supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
     * clients may also implement other ways to allow the current volume level to
     * be changed, for example, by providing a knob that the user can turn.)
     * </pre>
     *
     * <code>optional int32 volume_percentage = 4;</code>
     */
    public int getVolumePercentage() {
      return instance.getVolumePercentage();
    }
    /**
     * <pre>
     * *Output-only* Updated volume level. The value will be 0 or omitted
     * (indicating no change) unless a voice command such as *Increase the volume*
     * or *Set volume level 4* was recognized, in which case the value will be
     * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
     * Typically, a client should use this volume level when playing the
     * `audio_out` data, and retain this value as the current volume level and
     * supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
     * clients may also implement other ways to allow the current volume level to
     * be changed, for example, by providing a knob that the user can turn.)
     * </pre>
     *
     * <code>optional int32 volume_percentage = 4;</code>
     */
    public Builder setVolumePercentage(int value) {
      copyOnWrite();
      instance.setVolumePercentage(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Updated volume level. The value will be 0 or omitted
     * (indicating no change) unless a voice command such as *Increase the volume*
     * or *Set volume level 4* was recognized, in which case the value will be
     * between 1 and 100 (corresponding to the new volume level of 1% to 100%).
     * Typically, a client should use this volume level when playing the
     * `audio_out` data, and retain this value as the current volume level and
     * supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
     * clients may also implement other ways to allow the current volume level to
     * be changed, for example, by providing a knob that the user can turn.)
     * </pre>
     *
     * <code>optional int32 volume_percentage = 4;</code>
     */
    public Builder clearVolumePercentage() {
      copyOnWrite();
      instance.clearVolumePercentage();
      return this;
    }

    // @@protoc_insertion_point(builder_scope:google.assistant.embedded.v1alpha2.DialogStateOut)
  }
  protected final Object dynamicMethod(
      com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
      Object arg0, Object arg1) {
    switch (method) {
      case NEW_MUTABLE_INSTANCE: {
        return new com.google.assistant.embedded.v1alpha2.DialogStateOut();
      }
      case IS_INITIALIZED: {
        return DEFAULT_INSTANCE;
      }
      case MAKE_IMMUTABLE: {
        return null;
      }
      case NEW_BUILDER: {
        return new Builder();
      }
      case VISIT: {
        Visitor visitor = (Visitor) arg0;
        com.google.assistant.embedded.v1alpha2.DialogStateOut other = (com.google.assistant.embedded.v1alpha2.DialogStateOut) arg1;
        supplementalDisplayText_ = visitor.visitString(!supplementalDisplayText_.isEmpty(), supplementalDisplayText_,
            !other.supplementalDisplayText_.isEmpty(), other.supplementalDisplayText_);
        conversationState_ = visitor.visitByteString(conversationState_ != com.google.protobuf.ByteString.EMPTY, conversationState_,
            other.conversationState_ != com.google.protobuf.ByteString.EMPTY, other.conversationState_);
        microphoneMode_ = visitor.visitInt(microphoneMode_ != 0, microphoneMode_,    other.microphoneMode_ != 0, other.microphoneMode_);
        volumePercentage_ = visitor.visitInt(volumePercentage_ != 0, volumePercentage_,
            other.volumePercentage_ != 0, other.volumePercentage_);
        if (visitor == com.google.protobuf.GeneratedMessageLite.MergeFromVisitor
            .INSTANCE) {
        }
        return this;
      }
      case MERGE_FROM_STREAM: {
        com.google.protobuf.CodedInputStream input =
            (com.google.protobuf.CodedInputStream) arg0;
        com.google.protobuf.ExtensionRegistryLite extensionRegistry =
            (com.google.protobuf.ExtensionRegistryLite) arg1;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                String s = input.readStringRequireUtf8();

                supplementalDisplayText_ = s;
                break;
              }
              case 18: {

                conversationState_ = input.readBytes();
                break;
              }
              case 24: {
                int rawValue = input.readEnum();

                microphoneMode_ = rawValue;
                break;
              }
              case 32: {

                volumePercentage_ = input.readInt32();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw new RuntimeException(e.setUnfinishedMessage(this));
        } catch (java.io.IOException e) {
          throw new RuntimeException(
              new com.google.protobuf.InvalidProtocolBufferException(
                  e.getMessage()).setUnfinishedMessage(this));
        } finally {
        }
      }
      case GET_DEFAULT_INSTANCE: {
        return DEFAULT_INSTANCE;
      }
      case GET_PARSER: {
        if (PARSER == null) {    synchronized (com.google.assistant.embedded.v1alpha2.DialogStateOut.class) {
            if (PARSER == null) {
              PARSER = new DefaultInstanceBasedParser(DEFAULT_INSTANCE);
            }
          }
        }
        return PARSER;
      }
    }
    throw new UnsupportedOperationException();
  }


  // @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha2.DialogStateOut)
  private static final com.google.assistant.embedded.v1alpha2.DialogStateOut DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new DialogStateOut();
    DEFAULT_INSTANCE.makeImmutable();
  }

  public static com.google.assistant.embedded.v1alpha2.DialogStateOut getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static volatile com.google.protobuf.Parser<DialogStateOut> PARSER;

  public static com.google.protobuf.Parser<DialogStateOut> parser() {
    return DEFAULT_INSTANCE.getParserForType();
  }
}

