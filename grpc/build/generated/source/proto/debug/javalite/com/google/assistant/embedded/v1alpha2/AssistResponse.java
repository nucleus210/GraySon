// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/assistant/embedded/v1alpha2/embedded_assistant.proto

package com.google.assistant.embedded.v1alpha2;

/**
 * <pre>
 * The top-level message received by the client. A series of one or more
 * `AssistResponse` messages are streamed back to the client.
 * </pre>
 *
 * Protobuf type {@code google.assistant.embedded.v1alpha2.AssistResponse}
 */
public  final class AssistResponse extends
    com.google.protobuf.GeneratedMessageLite<
        AssistResponse, AssistResponse.Builder> implements
    // @@protoc_insertion_point(message_implements:google.assistant.embedded.v1alpha2.AssistResponse)
    AssistResponseOrBuilder {
  private AssistResponse() {
    speechResults_ = emptyProtobufList();
  }
  /**
   * <pre>
   * Indicates the type of event.
   * </pre>
   *
   * Protobuf enum {@code google.assistant.embedded.v1alpha2.AssistResponse.EventType}
   */
  public enum EventType
      implements com.google.protobuf.Internal.EnumLite {
    /**
     * <pre>
     * No event specified.
     * </pre>
     *
     * <code>EVENT_TYPE_UNSPECIFIED = 0;</code>
     */
    EVENT_TYPE_UNSPECIFIED(0),
    /**
     * <pre>
     * This event indicates that the server has detected the end of the user's
     * speech utterance and expects no additional speech. Therefore, the server
     * will not process additional audio (although it may subsequently return
     * additional results). The client should stop sending additional audio
     * data, half-close the gRPC connection, and wait for any additional results
     * until the server closes the gRPC connection.
     * </pre>
     *
     * <code>END_OF_UTTERANCE = 1;</code>
     */
    END_OF_UTTERANCE(1),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * No event specified.
     * </pre>
     *
     * <code>EVENT_TYPE_UNSPECIFIED = 0;</code>
     */
    public static final int EVENT_TYPE_UNSPECIFIED_VALUE = 0;
    /**
     * <pre>
     * This event indicates that the server has detected the end of the user's
     * speech utterance and expects no additional speech. Therefore, the server
     * will not process additional audio (although it may subsequently return
     * additional results). The client should stop sending additional audio
     * data, half-close the gRPC connection, and wait for any additional results
     * until the server closes the gRPC connection.
     * </pre>
     *
     * <code>END_OF_UTTERANCE = 1;</code>
     */
    public static final int END_OF_UTTERANCE_VALUE = 1;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static EventType valueOf(int value) {
      return forNumber(value);
    }

    public static EventType forNumber(int value) {
      switch (value) {
        case 0: return EVENT_TYPE_UNSPECIFIED;
        case 1: return END_OF_UTTERANCE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<EventType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        EventType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<EventType>() {
            public EventType findValueByNumber(int number) {
              return EventType.forNumber(number);
            }
          };

    private final int value;

    private EventType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:google.assistant.embedded.v1alpha2.AssistResponse.EventType)
  }

  private int bitField0_;
  public static final int EVENT_TYPE_FIELD_NUMBER = 1;
  private int eventType_;
  /**
   * <pre>
   * *Output-only* Indicates the type of event.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
   */
  public int getEventTypeValue() {
    return eventType_;
  }
  /**
   * <pre>
   * *Output-only* Indicates the type of event.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
   */
  public com.google.assistant.embedded.v1alpha2.AssistResponse.EventType getEventType() {
    com.google.assistant.embedded.v1alpha2.AssistResponse.EventType result = com.google.assistant.embedded.v1alpha2.AssistResponse.EventType.forNumber(eventType_);
    return result == null ? com.google.assistant.embedded.v1alpha2.AssistResponse.EventType.UNRECOGNIZED : result;
  }
  /**
   * <pre>
   * *Output-only* Indicates the type of event.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
   */
  private void setEventTypeValue(int value) {
      eventType_ = value;
  }
  /**
   * <pre>
   * *Output-only* Indicates the type of event.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
   */
  private void setEventType(com.google.assistant.embedded.v1alpha2.AssistResponse.EventType value) {
    if (value == null) {
      throw new NullPointerException();
    }
    
    eventType_ = value.getNumber();
  }
  /**
   * <pre>
   * *Output-only* Indicates the type of event.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
   */
  private void clearEventType() {
    
    eventType_ = 0;
  }

  public static final int AUDIO_OUT_FIELD_NUMBER = 3;
  private com.google.assistant.embedded.v1alpha2.AudioOut audioOut_;
  /**
   * <pre>
   * *Output-only* The audio containing the Assistant's response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
   */
  public boolean hasAudioOut() {
    return audioOut_ != null;
  }
  /**
   * <pre>
   * *Output-only* The audio containing the Assistant's response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
   */
  public com.google.assistant.embedded.v1alpha2.AudioOut getAudioOut() {
    return audioOut_ == null ? com.google.assistant.embedded.v1alpha2.AudioOut.getDefaultInstance() : audioOut_;
  }
  /**
   * <pre>
   * *Output-only* The audio containing the Assistant's response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
   */
  private void setAudioOut(com.google.assistant.embedded.v1alpha2.AudioOut value) {
    if (value == null) {
      throw new NullPointerException();
    }
    audioOut_ = value;
    
    }
  /**
   * <pre>
   * *Output-only* The audio containing the Assistant's response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
   */
  private void setAudioOut(
      com.google.assistant.embedded.v1alpha2.AudioOut.Builder builderForValue) {
    audioOut_ = builderForValue.build();
    
  }
  /**
   * <pre>
   * *Output-only* The audio containing the Assistant's response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
   */
  private void mergeAudioOut(com.google.assistant.embedded.v1alpha2.AudioOut value) {
    if (audioOut_ != null &&
        audioOut_ != com.google.assistant.embedded.v1alpha2.AudioOut.getDefaultInstance()) {
      audioOut_ =
        com.google.assistant.embedded.v1alpha2.AudioOut.newBuilder(audioOut_).mergeFrom(value).buildPartial();
    } else {
      audioOut_ = value;
    }
    
  }
  /**
   * <pre>
   * *Output-only* The audio containing the Assistant's response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
   */
  private void clearAudioOut() {  audioOut_ = null;
    
  }

  public static final int SCREEN_OUT_FIELD_NUMBER = 4;
  private com.google.assistant.embedded.v1alpha2.ScreenOut screenOut_;
  /**
   * <pre>
   * *Output-only* Contains the Assistant's visual response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
   */
  public boolean hasScreenOut() {
    return screenOut_ != null;
  }
  /**
   * <pre>
   * *Output-only* Contains the Assistant's visual response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
   */
  public com.google.assistant.embedded.v1alpha2.ScreenOut getScreenOut() {
    return screenOut_ == null ? com.google.assistant.embedded.v1alpha2.ScreenOut.getDefaultInstance() : screenOut_;
  }
  /**
   * <pre>
   * *Output-only* Contains the Assistant's visual response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
   */
  private void setScreenOut(com.google.assistant.embedded.v1alpha2.ScreenOut value) {
    if (value == null) {
      throw new NullPointerException();
    }
    screenOut_ = value;
    
    }
  /**
   * <pre>
   * *Output-only* Contains the Assistant's visual response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
   */
  private void setScreenOut(
      com.google.assistant.embedded.v1alpha2.ScreenOut.Builder builderForValue) {
    screenOut_ = builderForValue.build();
    
  }
  /**
   * <pre>
   * *Output-only* Contains the Assistant's visual response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
   */
  private void mergeScreenOut(com.google.assistant.embedded.v1alpha2.ScreenOut value) {
    if (screenOut_ != null &&
        screenOut_ != com.google.assistant.embedded.v1alpha2.ScreenOut.getDefaultInstance()) {
      screenOut_ =
        com.google.assistant.embedded.v1alpha2.ScreenOut.newBuilder(screenOut_).mergeFrom(value).buildPartial();
    } else {
      screenOut_ = value;
    }
    
  }
  /**
   * <pre>
   * *Output-only* Contains the Assistant's visual response to the query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
   */
  private void clearScreenOut() {  screenOut_ = null;
    
  }

  public static final int DEVICE_ACTION_FIELD_NUMBER = 6;
  private com.google.assistant.embedded.v1alpha2.DeviceAction deviceAction_;
  /**
   * <pre>
   * *Output-only* Contains the action triggered by the query with the
   * appropriate payloads and semantic parsing.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
   */
  public boolean hasDeviceAction() {
    return deviceAction_ != null;
  }
  /**
   * <pre>
   * *Output-only* Contains the action triggered by the query with the
   * appropriate payloads and semantic parsing.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
   */
  public com.google.assistant.embedded.v1alpha2.DeviceAction getDeviceAction() {
    return deviceAction_ == null ? com.google.assistant.embedded.v1alpha2.DeviceAction.getDefaultInstance() : deviceAction_;
  }
  /**
   * <pre>
   * *Output-only* Contains the action triggered by the query with the
   * appropriate payloads and semantic parsing.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
   */
  private void setDeviceAction(com.google.assistant.embedded.v1alpha2.DeviceAction value) {
    if (value == null) {
      throw new NullPointerException();
    }
    deviceAction_ = value;
    
    }
  /**
   * <pre>
   * *Output-only* Contains the action triggered by the query with the
   * appropriate payloads and semantic parsing.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
   */
  private void setDeviceAction(
      com.google.assistant.embedded.v1alpha2.DeviceAction.Builder builderForValue) {
    deviceAction_ = builderForValue.build();
    
  }
  /**
   * <pre>
   * *Output-only* Contains the action triggered by the query with the
   * appropriate payloads and semantic parsing.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
   */
  private void mergeDeviceAction(com.google.assistant.embedded.v1alpha2.DeviceAction value) {
    if (deviceAction_ != null &&
        deviceAction_ != com.google.assistant.embedded.v1alpha2.DeviceAction.getDefaultInstance()) {
      deviceAction_ =
        com.google.assistant.embedded.v1alpha2.DeviceAction.newBuilder(deviceAction_).mergeFrom(value).buildPartial();
    } else {
      deviceAction_ = value;
    }
    
  }
  /**
   * <pre>
   * *Output-only* Contains the action triggered by the query with the
   * appropriate payloads and semantic parsing.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
   */
  private void clearDeviceAction() {  deviceAction_ = null;
    
  }

  public static final int SPEECH_RESULTS_FIELD_NUMBER = 2;
  private com.google.protobuf.Internal.ProtobufList<com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult> speechResults_;
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  public java.util.List<com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult> getSpeechResultsList() {
    return speechResults_;
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  public java.util.List<? extends com.google.assistant.embedded.v1alpha2.SpeechRecognitionResultOrBuilder> 
      getSpeechResultsOrBuilderList() {
    return speechResults_;
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  public int getSpeechResultsCount() {
    return speechResults_.size();
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  public com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult getSpeechResults(int index) {
    return speechResults_.get(index);
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  public com.google.assistant.embedded.v1alpha2.SpeechRecognitionResultOrBuilder getSpeechResultsOrBuilder(
      int index) {
    return speechResults_.get(index);
  }
  private void ensureSpeechResultsIsMutable() {
    if (!speechResults_.isModifiable()) {
      speechResults_ =
          com.google.protobuf.GeneratedMessageLite.mutableCopy(speechResults_);
     }
  }

  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void setSpeechResults(
      int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult value) {
    if (value == null) {
      throw new NullPointerException();
    }
    ensureSpeechResultsIsMutable();
    speechResults_.set(index, value);
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void setSpeechResults(
      int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.Builder builderForValue) {
    ensureSpeechResultsIsMutable();
    speechResults_.set(index, builderForValue.build());
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void addSpeechResults(com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult value) {
    if (value == null) {
      throw new NullPointerException();
    }
    ensureSpeechResultsIsMutable();
    speechResults_.add(value);
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void addSpeechResults(
      int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult value) {
    if (value == null) {
      throw new NullPointerException();
    }
    ensureSpeechResultsIsMutable();
    speechResults_.add(index, value);
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void addSpeechResults(
      com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.Builder builderForValue) {
    ensureSpeechResultsIsMutable();
    speechResults_.add(builderForValue.build());
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void addSpeechResults(
      int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.Builder builderForValue) {
    ensureSpeechResultsIsMutable();
    speechResults_.add(index, builderForValue.build());
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void addAllSpeechResults(
      java.lang.Iterable<? extends com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult> values) {
    ensureSpeechResultsIsMutable();
    com.google.protobuf.AbstractMessageLite.addAll(
        values, speechResults_);
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void clearSpeechResults() {
    speechResults_ = emptyProtobufList();
  }
  /**
   * <pre>
   * *Output-only* This repeated list contains zero or more speech recognition
   * results that correspond to consecutive portions of the audio currently
   * being processed, starting with the portion corresponding to the earliest
   * audio (and most stable portion) to the portion corresponding to the most
   * recent audio. The strings can be concatenated to view the full
   * in-progress response. When the speech recognition completes, this list
   * will contain one item with `stability` of `1.0`.
   * </pre>
   *
   * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
   */
  private void removeSpeechResults(int index) {
    ensureSpeechResultsIsMutable();
    speechResults_.remove(index);
  }

  public static final int DIALOG_STATE_OUT_FIELD_NUMBER = 5;
  private com.google.assistant.embedded.v1alpha2.DialogStateOut dialogStateOut_;
  /**
   * <pre>
   * *Output-only* Contains output related to the user's query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
   */
  public boolean hasDialogStateOut() {
    return dialogStateOut_ != null;
  }
  /**
   * <pre>
   * *Output-only* Contains output related to the user's query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
   */
  public com.google.assistant.embedded.v1alpha2.DialogStateOut getDialogStateOut() {
    return dialogStateOut_ == null ? com.google.assistant.embedded.v1alpha2.DialogStateOut.getDefaultInstance() : dialogStateOut_;
  }
  /**
   * <pre>
   * *Output-only* Contains output related to the user's query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
   */
  private void setDialogStateOut(com.google.assistant.embedded.v1alpha2.DialogStateOut value) {
    if (value == null) {
      throw new NullPointerException();
    }
    dialogStateOut_ = value;
    
    }
  /**
   * <pre>
   * *Output-only* Contains output related to the user's query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
   */
  private void setDialogStateOut(
      com.google.assistant.embedded.v1alpha2.DialogStateOut.Builder builderForValue) {
    dialogStateOut_ = builderForValue.build();
    
  }
  /**
   * <pre>
   * *Output-only* Contains output related to the user's query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
   */
  private void mergeDialogStateOut(com.google.assistant.embedded.v1alpha2.DialogStateOut value) {
    if (dialogStateOut_ != null &&
        dialogStateOut_ != com.google.assistant.embedded.v1alpha2.DialogStateOut.getDefaultInstance()) {
      dialogStateOut_ =
        com.google.assistant.embedded.v1alpha2.DialogStateOut.newBuilder(dialogStateOut_).mergeFrom(value).buildPartial();
    } else {
      dialogStateOut_ = value;
    }
    
  }
  /**
   * <pre>
   * *Output-only* Contains output related to the user's query.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
   */
  private void clearDialogStateOut() {  dialogStateOut_ = null;
    
  }

  public static final int DEBUG_INFO_FIELD_NUMBER = 8;
  private com.google.assistant.embedded.v1alpha2.DebugInfo debugInfo_;
  /**
   * <pre>
   * *Output-only* Debugging output that is returned if DebugConfig was set in
   * the AssistConfig
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
   */
  public boolean hasDebugInfo() {
    return debugInfo_ != null;
  }
  /**
   * <pre>
   * *Output-only* Debugging output that is returned if DebugConfig was set in
   * the AssistConfig
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
   */
  public com.google.assistant.embedded.v1alpha2.DebugInfo getDebugInfo() {
    return debugInfo_ == null ? com.google.assistant.embedded.v1alpha2.DebugInfo.getDefaultInstance() : debugInfo_;
  }
  /**
   * <pre>
   * *Output-only* Debugging output that is returned if DebugConfig was set in
   * the AssistConfig
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
   */
  private void setDebugInfo(com.google.assistant.embedded.v1alpha2.DebugInfo value) {
    if (value == null) {
      throw new NullPointerException();
    }
    debugInfo_ = value;
    
    }
  /**
   * <pre>
   * *Output-only* Debugging output that is returned if DebugConfig was set in
   * the AssistConfig
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
   */
  private void setDebugInfo(
      com.google.assistant.embedded.v1alpha2.DebugInfo.Builder builderForValue) {
    debugInfo_ = builderForValue.build();
    
  }
  /**
   * <pre>
   * *Output-only* Debugging output that is returned if DebugConfig was set in
   * the AssistConfig
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
   */
  private void mergeDebugInfo(com.google.assistant.embedded.v1alpha2.DebugInfo value) {
    if (debugInfo_ != null &&
        debugInfo_ != com.google.assistant.embedded.v1alpha2.DebugInfo.getDefaultInstance()) {
      debugInfo_ =
        com.google.assistant.embedded.v1alpha2.DebugInfo.newBuilder(debugInfo_).mergeFrom(value).buildPartial();
    } else {
      debugInfo_ = value;
    }
    
  }
  /**
   * <pre>
   * *Output-only* Debugging output that is returned if DebugConfig was set in
   * the AssistConfig
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
   */
  private void clearDebugInfo() {  debugInfo_ = null;
    
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (eventType_ != com.google.assistant.embedded.v1alpha2.AssistResponse.EventType.EVENT_TYPE_UNSPECIFIED.getNumber()) {
      output.writeEnum(1, eventType_);
    }
    for (int i = 0; i < speechResults_.size(); i++) {
      output.writeMessage(2, speechResults_.get(i));
    }
    if (audioOut_ != null) {
      output.writeMessage(3, getAudioOut());
    }
    if (screenOut_ != null) {
      output.writeMessage(4, getScreenOut());
    }
    if (dialogStateOut_ != null) {
      output.writeMessage(5, getDialogStateOut());
    }
    if (deviceAction_ != null) {
      output.writeMessage(6, getDeviceAction());
    }
    if (debugInfo_ != null) {
      output.writeMessage(8, getDebugInfo());
    }
  }

  public int getSerializedSize() {
    int size = memoizedSerializedSize;
    if (size != -1) return size;

    size = 0;
    if (eventType_ != com.google.assistant.embedded.v1alpha2.AssistResponse.EventType.EVENT_TYPE_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(1, eventType_);
    }
    for (int i = 0; i < speechResults_.size(); i++) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(2, speechResults_.get(i));
    }
    if (audioOut_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(3, getAudioOut());
    }
    if (screenOut_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(4, getScreenOut());
    }
    if (dialogStateOut_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(5, getDialogStateOut());
    }
    if (deviceAction_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(6, getDeviceAction());
    }
    if (debugInfo_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(8, getDebugInfo());
    }
    memoizedSerializedSize = size;
    return size;
  }

  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistResponse parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.assistant.embedded.v1alpha2.AssistResponse prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  /**
   * <pre>
   * The top-level message received by the client. A series of one or more
   * `AssistResponse` messages are streamed back to the client.
   * </pre>
   *
   * Protobuf type {@code google.assistant.embedded.v1alpha2.AssistResponse}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageLite.Builder<
        com.google.assistant.embedded.v1alpha2.AssistResponse, Builder> implements
      // @@protoc_insertion_point(builder_implements:google.assistant.embedded.v1alpha2.AssistResponse)
      com.google.assistant.embedded.v1alpha2.AssistResponseOrBuilder {
    // Construct using com.google.assistant.embedded.v1alpha2.AssistResponse.newBuilder()
    private Builder() {
      super(DEFAULT_INSTANCE);
    }


    /**
     * <pre>
     * *Output-only* Indicates the type of event.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
     */
    public int getEventTypeValue() {
      return instance.getEventTypeValue();
    }
    /**
     * <pre>
     * *Output-only* Indicates the type of event.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
     */
    public Builder setEventTypeValue(int value) {
      copyOnWrite();
      instance.setEventTypeValue(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Indicates the type of event.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
     */
    public com.google.assistant.embedded.v1alpha2.AssistResponse.EventType getEventType() {
      return instance.getEventType();
    }
    /**
     * <pre>
     * *Output-only* Indicates the type of event.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
     */
    public Builder setEventType(com.google.assistant.embedded.v1alpha2.AssistResponse.EventType value) {
      copyOnWrite();
      instance.setEventType(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Indicates the type of event.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistResponse.EventType event_type = 1;</code>
     */
    public Builder clearEventType() {
      copyOnWrite();
      instance.clearEventType();
      return this;
    }

    /**
     * <pre>
     * *Output-only* The audio containing the Assistant's response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
     */
    public boolean hasAudioOut() {
      return instance.hasAudioOut();
    }
    /**
     * <pre>
     * *Output-only* The audio containing the Assistant's response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
     */
    public com.google.assistant.embedded.v1alpha2.AudioOut getAudioOut() {
      return instance.getAudioOut();
    }
    /**
     * <pre>
     * *Output-only* The audio containing the Assistant's response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
     */
    public Builder setAudioOut(com.google.assistant.embedded.v1alpha2.AudioOut value) {
      copyOnWrite();
      instance.setAudioOut(value);
      return this;
      }
    /**
     * <pre>
     * *Output-only* The audio containing the Assistant's response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
     */
    public Builder setAudioOut(
        com.google.assistant.embedded.v1alpha2.AudioOut.Builder builderForValue) {
      copyOnWrite();
      instance.setAudioOut(builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* The audio containing the Assistant's response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
     */
    public Builder mergeAudioOut(com.google.assistant.embedded.v1alpha2.AudioOut value) {
      copyOnWrite();
      instance.mergeAudioOut(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* The audio containing the Assistant's response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AudioOut audio_out = 3;</code>
     */
    public Builder clearAudioOut() {  copyOnWrite();
      instance.clearAudioOut();
      return this;
    }

    /**
     * <pre>
     * *Output-only* Contains the Assistant's visual response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
     */
    public boolean hasScreenOut() {
      return instance.hasScreenOut();
    }
    /**
     * <pre>
     * *Output-only* Contains the Assistant's visual response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
     */
    public com.google.assistant.embedded.v1alpha2.ScreenOut getScreenOut() {
      return instance.getScreenOut();
    }
    /**
     * <pre>
     * *Output-only* Contains the Assistant's visual response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
     */
    public Builder setScreenOut(com.google.assistant.embedded.v1alpha2.ScreenOut value) {
      copyOnWrite();
      instance.setScreenOut(value);
      return this;
      }
    /**
     * <pre>
     * *Output-only* Contains the Assistant's visual response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
     */
    public Builder setScreenOut(
        com.google.assistant.embedded.v1alpha2.ScreenOut.Builder builderForValue) {
      copyOnWrite();
      instance.setScreenOut(builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Contains the Assistant's visual response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
     */
    public Builder mergeScreenOut(com.google.assistant.embedded.v1alpha2.ScreenOut value) {
      copyOnWrite();
      instance.mergeScreenOut(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Contains the Assistant's visual response to the query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.ScreenOut screen_out = 4;</code>
     */
    public Builder clearScreenOut() {  copyOnWrite();
      instance.clearScreenOut();
      return this;
    }

    /**
     * <pre>
     * *Output-only* Contains the action triggered by the query with the
     * appropriate payloads and semantic parsing.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
     */
    public boolean hasDeviceAction() {
      return instance.hasDeviceAction();
    }
    /**
     * <pre>
     * *Output-only* Contains the action triggered by the query with the
     * appropriate payloads and semantic parsing.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
     */
    public com.google.assistant.embedded.v1alpha2.DeviceAction getDeviceAction() {
      return instance.getDeviceAction();
    }
    /**
     * <pre>
     * *Output-only* Contains the action triggered by the query with the
     * appropriate payloads and semantic parsing.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
     */
    public Builder setDeviceAction(com.google.assistant.embedded.v1alpha2.DeviceAction value) {
      copyOnWrite();
      instance.setDeviceAction(value);
      return this;
      }
    /**
     * <pre>
     * *Output-only* Contains the action triggered by the query with the
     * appropriate payloads and semantic parsing.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
     */
    public Builder setDeviceAction(
        com.google.assistant.embedded.v1alpha2.DeviceAction.Builder builderForValue) {
      copyOnWrite();
      instance.setDeviceAction(builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Contains the action triggered by the query with the
     * appropriate payloads and semantic parsing.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
     */
    public Builder mergeDeviceAction(com.google.assistant.embedded.v1alpha2.DeviceAction value) {
      copyOnWrite();
      instance.mergeDeviceAction(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Contains the action triggered by the query with the
     * appropriate payloads and semantic parsing.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DeviceAction device_action = 6;</code>
     */
    public Builder clearDeviceAction() {  copyOnWrite();
      instance.clearDeviceAction();
      return this;
    }

    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public java.util.List<com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult> getSpeechResultsList() {
      return java.util.Collections.unmodifiableList(
          instance.getSpeechResultsList());
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public int getSpeechResultsCount() {
      return instance.getSpeechResultsCount();
    }/**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult getSpeechResults(int index) {
      return instance.getSpeechResults(index);
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder setSpeechResults(
        int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult value) {
      copyOnWrite();
      instance.setSpeechResults(index, value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder setSpeechResults(
        int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.Builder builderForValue) {
      copyOnWrite();
      instance.setSpeechResults(index, builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder addSpeechResults(com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult value) {
      copyOnWrite();
      instance.addSpeechResults(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder addSpeechResults(
        int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult value) {
      copyOnWrite();
      instance.addSpeechResults(index, value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder addSpeechResults(
        com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.Builder builderForValue) {
      copyOnWrite();
      instance.addSpeechResults(builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder addSpeechResults(
        int index, com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.Builder builderForValue) {
      copyOnWrite();
      instance.addSpeechResults(index, builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder addAllSpeechResults(
        java.lang.Iterable<? extends com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult> values) {
      copyOnWrite();
      instance.addAllSpeechResults(values);
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder clearSpeechResults() {
      copyOnWrite();
      instance.clearSpeechResults();
      return this;
    }
    /**
     * <pre>
     * *Output-only* This repeated list contains zero or more speech recognition
     * results that correspond to consecutive portions of the audio currently
     * being processed, starting with the portion corresponding to the earliest
     * audio (and most stable portion) to the portion corresponding to the most
     * recent audio. The strings can be concatenated to view the full
     * in-progress response. When the speech recognition completes, this list
     * will contain one item with `stability` of `1.0`.
     * </pre>
     *
     * <code>repeated .google.assistant.embedded.v1alpha2.SpeechRecognitionResult speech_results = 2;</code>
     */
    public Builder removeSpeechResults(int index) {
      copyOnWrite();
      instance.removeSpeechResults(index);
      return this;
    }

    /**
     * <pre>
     * *Output-only* Contains output related to the user's query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
     */
    public boolean hasDialogStateOut() {
      return instance.hasDialogStateOut();
    }
    /**
     * <pre>
     * *Output-only* Contains output related to the user's query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
     */
    public com.google.assistant.embedded.v1alpha2.DialogStateOut getDialogStateOut() {
      return instance.getDialogStateOut();
    }
    /**
     * <pre>
     * *Output-only* Contains output related to the user's query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
     */
    public Builder setDialogStateOut(com.google.assistant.embedded.v1alpha2.DialogStateOut value) {
      copyOnWrite();
      instance.setDialogStateOut(value);
      return this;
      }
    /**
     * <pre>
     * *Output-only* Contains output related to the user's query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
     */
    public Builder setDialogStateOut(
        com.google.assistant.embedded.v1alpha2.DialogStateOut.Builder builderForValue) {
      copyOnWrite();
      instance.setDialogStateOut(builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Contains output related to the user's query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
     */
    public Builder mergeDialogStateOut(com.google.assistant.embedded.v1alpha2.DialogStateOut value) {
      copyOnWrite();
      instance.mergeDialogStateOut(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Contains output related to the user's query.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DialogStateOut dialog_state_out = 5;</code>
     */
    public Builder clearDialogStateOut() {  copyOnWrite();
      instance.clearDialogStateOut();
      return this;
    }

    /**
     * <pre>
     * *Output-only* Debugging output that is returned if DebugConfig was set in
     * the AssistConfig
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
     */
    public boolean hasDebugInfo() {
      return instance.hasDebugInfo();
    }
    /**
     * <pre>
     * *Output-only* Debugging output that is returned if DebugConfig was set in
     * the AssistConfig
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
     */
    public com.google.assistant.embedded.v1alpha2.DebugInfo getDebugInfo() {
      return instance.getDebugInfo();
    }
    /**
     * <pre>
     * *Output-only* Debugging output that is returned if DebugConfig was set in
     * the AssistConfig
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
     */
    public Builder setDebugInfo(com.google.assistant.embedded.v1alpha2.DebugInfo value) {
      copyOnWrite();
      instance.setDebugInfo(value);
      return this;
      }
    /**
     * <pre>
     * *Output-only* Debugging output that is returned if DebugConfig was set in
     * the AssistConfig
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
     */
    public Builder setDebugInfo(
        com.google.assistant.embedded.v1alpha2.DebugInfo.Builder builderForValue) {
      copyOnWrite();
      instance.setDebugInfo(builderForValue);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Debugging output that is returned if DebugConfig was set in
     * the AssistConfig
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
     */
    public Builder mergeDebugInfo(com.google.assistant.embedded.v1alpha2.DebugInfo value) {
      copyOnWrite();
      instance.mergeDebugInfo(value);
      return this;
    }
    /**
     * <pre>
     * *Output-only* Debugging output that is returned if DebugConfig was set in
     * the AssistConfig
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.DebugInfo debug_info = 8;</code>
     */
    public Builder clearDebugInfo() {  copyOnWrite();
      instance.clearDebugInfo();
      return this;
    }

    // @@protoc_insertion_point(builder_scope:google.assistant.embedded.v1alpha2.AssistResponse)
  }
  protected final Object dynamicMethod(
      com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
      Object arg0, Object arg1) {
    switch (method) {
      case NEW_MUTABLE_INSTANCE: {
        return new com.google.assistant.embedded.v1alpha2.AssistResponse();
      }
      case IS_INITIALIZED: {
        return DEFAULT_INSTANCE;
      }
      case MAKE_IMMUTABLE: {
        speechResults_.makeImmutable();
        return null;
      }
      case NEW_BUILDER: {
        return new Builder();
      }
      case VISIT: {
        Visitor visitor = (Visitor) arg0;
        com.google.assistant.embedded.v1alpha2.AssistResponse other = (com.google.assistant.embedded.v1alpha2.AssistResponse) arg1;
        eventType_ = visitor.visitInt(eventType_ != 0, eventType_,    other.eventType_ != 0, other.eventType_);
        audioOut_ = visitor.visitMessage(audioOut_, other.audioOut_);
        screenOut_ = visitor.visitMessage(screenOut_, other.screenOut_);
        deviceAction_ = visitor.visitMessage(deviceAction_, other.deviceAction_);
        speechResults_= visitor.visitList(speechResults_, other.speechResults_);
        dialogStateOut_ = visitor.visitMessage(dialogStateOut_, other.dialogStateOut_);
        debugInfo_ = visitor.visitMessage(debugInfo_, other.debugInfo_);
        if (visitor == com.google.protobuf.GeneratedMessageLite.MergeFromVisitor
            .INSTANCE) {
          bitField0_ |= other.bitField0_;
        }
        return this;
      }
      case MERGE_FROM_STREAM: {
        com.google.protobuf.CodedInputStream input =
            (com.google.protobuf.CodedInputStream) arg0;
        com.google.protobuf.ExtensionRegistryLite extensionRegistry =
            (com.google.protobuf.ExtensionRegistryLite) arg1;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {
                int rawValue = input.readEnum();

                eventType_ = rawValue;
                break;
              }
              case 18: {
                if (!speechResults_.isModifiable()) {
                  speechResults_ =
                      com.google.protobuf.GeneratedMessageLite.mutableCopy(speechResults_);
                }
                speechResults_.add(
                    input.readMessage(com.google.assistant.embedded.v1alpha2.SpeechRecognitionResult.parser(), extensionRegistry));
                break;
              }
              case 26: {
                com.google.assistant.embedded.v1alpha2.AudioOut.Builder subBuilder = null;
                if (audioOut_ != null) {
                  subBuilder = audioOut_.toBuilder();
                }
                audioOut_ = input.readMessage(com.google.assistant.embedded.v1alpha2.AudioOut.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(audioOut_);
                  audioOut_ = subBuilder.buildPartial();
                }

                break;
              }
              case 34: {
                com.google.assistant.embedded.v1alpha2.ScreenOut.Builder subBuilder = null;
                if (screenOut_ != null) {
                  subBuilder = screenOut_.toBuilder();
                }
                screenOut_ = input.readMessage(com.google.assistant.embedded.v1alpha2.ScreenOut.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(screenOut_);
                  screenOut_ = subBuilder.buildPartial();
                }

                break;
              }
              case 42: {
                com.google.assistant.embedded.v1alpha2.DialogStateOut.Builder subBuilder = null;
                if (dialogStateOut_ != null) {
                  subBuilder = dialogStateOut_.toBuilder();
                }
                dialogStateOut_ = input.readMessage(com.google.assistant.embedded.v1alpha2.DialogStateOut.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(dialogStateOut_);
                  dialogStateOut_ = subBuilder.buildPartial();
                }

                break;
              }
              case 50: {
                com.google.assistant.embedded.v1alpha2.DeviceAction.Builder subBuilder = null;
                if (deviceAction_ != null) {
                  subBuilder = deviceAction_.toBuilder();
                }
                deviceAction_ = input.readMessage(com.google.assistant.embedded.v1alpha2.DeviceAction.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(deviceAction_);
                  deviceAction_ = subBuilder.buildPartial();
                }

                break;
              }
              case 66: {
                com.google.assistant.embedded.v1alpha2.DebugInfo.Builder subBuilder = null;
                if (debugInfo_ != null) {
                  subBuilder = debugInfo_.toBuilder();
                }
                debugInfo_ = input.readMessage(com.google.assistant.embedded.v1alpha2.DebugInfo.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom(debugInfo_);
                  debugInfo_ = subBuilder.buildPartial();
                }

                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw new RuntimeException(e.setUnfinishedMessage(this));
        } catch (java.io.IOException e) {
          throw new RuntimeException(
              new com.google.protobuf.InvalidProtocolBufferException(
                  e.getMessage()).setUnfinishedMessage(this));
        } finally {
        }
      }
      case GET_DEFAULT_INSTANCE: {
        return DEFAULT_INSTANCE;
      }
      case GET_PARSER: {
        if (PARSER == null) {    synchronized (com.google.assistant.embedded.v1alpha2.AssistResponse.class) {
            if (PARSER == null) {
              PARSER = new DefaultInstanceBasedParser(DEFAULT_INSTANCE);
            }
          }
        }
        return PARSER;
      }
    }
    throw new UnsupportedOperationException();
  }


  // @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha2.AssistResponse)
  private static final com.google.assistant.embedded.v1alpha2.AssistResponse DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new AssistResponse();
    DEFAULT_INSTANCE.makeImmutable();
  }

  public static com.google.assistant.embedded.v1alpha2.AssistResponse getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static volatile com.google.protobuf.Parser<AssistResponse> PARSER;

  public static com.google.protobuf.Parser<AssistResponse> parser() {
    return DEFAULT_INSTANCE.getParserForType();
  }
}

