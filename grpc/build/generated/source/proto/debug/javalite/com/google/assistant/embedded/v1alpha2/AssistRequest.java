// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/assistant/embedded/v1alpha2/embedded_assistant.proto

package com.google.assistant.embedded.v1alpha2;

/**
 * <pre>
 * The top-level message sent by the client. Clients must send at least two, and
 * typically numerous `AssistRequest` messages. The first message must
 * contain a `config` message and must not contain `audio_in` data. All
 * subsequent messages must contain `audio_in` data and must not contain a
 * `config` message.
 * </pre>
 *
 * Protobuf type {@code google.assistant.embedded.v1alpha2.AssistRequest}
 */
public  final class AssistRequest extends
    com.google.protobuf.GeneratedMessageLite<
        AssistRequest, AssistRequest.Builder> implements
    // @@protoc_insertion_point(message_implements:google.assistant.embedded.v1alpha2.AssistRequest)
    AssistRequestOrBuilder {
  private AssistRequest() {
  }
  private int typeCase_ = 0;
  private java.lang.Object type_;
  public enum TypeCase
      implements com.google.protobuf.Internal.EnumLite {
    CONFIG(1),
    AUDIO_IN(2),
    TYPE_NOT_SET(0);
    private final int value;
    private TypeCase(int value) {
      this.value = value;
    }
    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static TypeCase valueOf(int value) {
      return forNumber(value);
    }

    public static TypeCase forNumber(int value) {
      switch (value) {
        case 1: return CONFIG;
        case 2: return AUDIO_IN;
        case 0: return TYPE_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  public TypeCase
  getTypeCase() {
    return TypeCase.forNumber(
        typeCase_);
  }

  private void clearType() {
    typeCase_ = 0;
    type_ = null;
  }

  public static final int CONFIG_FIELD_NUMBER = 1;
  /**
   * <pre>
   * The `config` message provides information to the recognizer that
   * specifies how to process the request.
   * The first `AssistRequest` message must contain a `config` message.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
   */
  public com.google.assistant.embedded.v1alpha2.AssistConfig getConfig() {
    if (typeCase_ == 1) {
       return (com.google.assistant.embedded.v1alpha2.AssistConfig) type_;
    }
    return com.google.assistant.embedded.v1alpha2.AssistConfig.getDefaultInstance();
  }
  /**
   * <pre>
   * The `config` message provides information to the recognizer that
   * specifies how to process the request.
   * The first `AssistRequest` message must contain a `config` message.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
   */
  private void setConfig(com.google.assistant.embedded.v1alpha2.AssistConfig value) {
    if (value == null) {
      throw new NullPointerException();
    }
    type_ = value;
    typeCase_ = 1;
  }
  /**
   * <pre>
   * The `config` message provides information to the recognizer that
   * specifies how to process the request.
   * The first `AssistRequest` message must contain a `config` message.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
   */
  private void setConfig(
      com.google.assistant.embedded.v1alpha2.AssistConfig.Builder builderForValue) {
    type_ = builderForValue.build();
    typeCase_ = 1;
  }
  /**
   * <pre>
   * The `config` message provides information to the recognizer that
   * specifies how to process the request.
   * The first `AssistRequest` message must contain a `config` message.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
   */
  private void mergeConfig(com.google.assistant.embedded.v1alpha2.AssistConfig value) {
    if (typeCase_ == 1 &&
        type_ != com.google.assistant.embedded.v1alpha2.AssistConfig.getDefaultInstance()) {
      type_ = com.google.assistant.embedded.v1alpha2.AssistConfig.newBuilder((com.google.assistant.embedded.v1alpha2.AssistConfig) type_)
          .mergeFrom(value).buildPartial();
    } else {
      type_ = value;
    }
    typeCase_ = 1;
  }
  /**
   * <pre>
   * The `config` message provides information to the recognizer that
   * specifies how to process the request.
   * The first `AssistRequest` message must contain a `config` message.
   * </pre>
   *
   * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
   */
  private void clearConfig() {
    if (typeCase_ == 1) {
      typeCase_ = 0;
      type_ = null;
    }
  }

  public static final int AUDIO_IN_FIELD_NUMBER = 2;
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `AssistRequest` messages. The first `AssistRequest`
   * message must not contain `audio_in` data and all subsequent
   * `AssistRequest` messages must contain `audio_in` data. The audio bytes
   * must be encoded as specified in `AudioInConfig`.
   * Audio must be sent at approximately real-time (16000 samples per second).
   * An error will be returned if audio is sent significantly faster or
   * slower.
   * If [AssistConfig.audio_in_config][] was not set in the first message,
   * then this field is not used. If it was set, this field is populated with
   * the audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `AssistRequest` messages. If 'AudioInConfig' is provided
   * in the first `AssistRequest` message, all subsequent `AssistRequest`
   * messages must contain `audio_in` data. The audio bytes must be encoded as
   * specified in `AudioInConfig`. Audio must be sent at approximately
   * real-time (16000 samples per second). An error will be returned if audio
   * is sent significantly faster or slower.
   * --)
   * </pre>
   *
   * <code>optional bytes audio_in = 2;</code>
   */
  public com.google.protobuf.ByteString getAudioIn() {
    if (typeCase_ == 2) {
      return (com.google.protobuf.ByteString) type_;
    }
    return com.google.protobuf.ByteString.EMPTY;
  }
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `AssistRequest` messages. The first `AssistRequest`
   * message must not contain `audio_in` data and all subsequent
   * `AssistRequest` messages must contain `audio_in` data. The audio bytes
   * must be encoded as specified in `AudioInConfig`.
   * Audio must be sent at approximately real-time (16000 samples per second).
   * An error will be returned if audio is sent significantly faster or
   * slower.
   * If [AssistConfig.audio_in_config][] was not set in the first message,
   * then this field is not used. If it was set, this field is populated with
   * the audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `AssistRequest` messages. If 'AudioInConfig' is provided
   * in the first `AssistRequest` message, all subsequent `AssistRequest`
   * messages must contain `audio_in` data. The audio bytes must be encoded as
   * specified in `AudioInConfig`. Audio must be sent at approximately
   * real-time (16000 samples per second). An error will be returned if audio
   * is sent significantly faster or slower.
   * --)
   * </pre>
   *
   * <code>optional bytes audio_in = 2;</code>
   */
  private void setAudioIn(com.google.protobuf.ByteString value) {
    if (value == null) {
    throw new NullPointerException();
  }
  typeCase_ = 2;
    type_ = value;
  }
  /**
   * <pre>
   * The audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `AssistRequest` messages. The first `AssistRequest`
   * message must not contain `audio_in` data and all subsequent
   * `AssistRequest` messages must contain `audio_in` data. The audio bytes
   * must be encoded as specified in `AudioInConfig`.
   * Audio must be sent at approximately real-time (16000 samples per second).
   * An error will be returned if audio is sent significantly faster or
   * slower.
   * If [AssistConfig.audio_in_config][] was not set in the first message,
   * then this field is not used. If it was set, this field is populated with
   * the audio data to be recognized. Sequential chunks of audio data are sent
   * in sequential `AssistRequest` messages. If 'AudioInConfig' is provided
   * in the first `AssistRequest` message, all subsequent `AssistRequest`
   * messages must contain `audio_in` data. The audio bytes must be encoded as
   * specified in `AudioInConfig`. Audio must be sent at approximately
   * real-time (16000 samples per second). An error will be returned if audio
   * is sent significantly faster or slower.
   * --)
   * </pre>
   *
   * <code>optional bytes audio_in = 2;</code>
   */
  private void clearAudioIn() {
    if (typeCase_ == 2) {
      typeCase_ = 0;
      type_ = null;
    }
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (typeCase_ == 1) {
      output.writeMessage(1, (com.google.assistant.embedded.v1alpha2.AssistConfig) type_);
    }
    if (typeCase_ == 2) {
      output.writeBytes(
          2, (com.google.protobuf.ByteString)((com.google.protobuf.ByteString) type_));
    }
  }

  public int getSerializedSize() {
    int size = memoizedSerializedSize;
    if (size != -1) return size;

    size = 0;
    if (typeCase_ == 1) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(1, (com.google.assistant.embedded.v1alpha2.AssistConfig) type_);
    }
    if (typeCase_ == 2) {
      size += com.google.protobuf.CodedOutputStream
        .computeBytesSize(
            2, (com.google.protobuf.ByteString)((com.google.protobuf.ByteString) type_));
    }
    memoizedSerializedSize = size;
    return size;
  }

  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, data, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return parseDelimitedFrom(DEFAULT_INSTANCE, input, extensionRegistry);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input);
  }
  public static com.google.assistant.embedded.v1alpha2.AssistRequest parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageLite.parseFrom(
        DEFAULT_INSTANCE, input, extensionRegistry);
  }

  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.assistant.embedded.v1alpha2.AssistRequest prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }

  /**
   * <pre>
   * The top-level message sent by the client. Clients must send at least two, and
   * typically numerous `AssistRequest` messages. The first message must
   * contain a `config` message and must not contain `audio_in` data. All
   * subsequent messages must contain `audio_in` data and must not contain a
   * `config` message.
   * </pre>
   *
   * Protobuf type {@code google.assistant.embedded.v1alpha2.AssistRequest}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageLite.Builder<
        com.google.assistant.embedded.v1alpha2.AssistRequest, Builder> implements
      // @@protoc_insertion_point(builder_implements:google.assistant.embedded.v1alpha2.AssistRequest)
      com.google.assistant.embedded.v1alpha2.AssistRequestOrBuilder {
    // Construct using com.google.assistant.embedded.v1alpha2.AssistRequest.newBuilder()
    private Builder() {
      super(DEFAULT_INSTANCE);
    }

    public TypeCase
        getTypeCase() {
      return instance.getTypeCase();
    }

    public Builder clearType() {
      copyOnWrite();
      instance.clearType();
      return this;
    }


    /**
     * <pre>
     * The `config` message provides information to the recognizer that
     * specifies how to process the request.
     * The first `AssistRequest` message must contain a `config` message.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
     */
    public com.google.assistant.embedded.v1alpha2.AssistConfig getConfig() {
      return instance.getConfig();
    }
    /**
     * <pre>
     * The `config` message provides information to the recognizer that
     * specifies how to process the request.
     * The first `AssistRequest` message must contain a `config` message.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
     */
    public Builder setConfig(com.google.assistant.embedded.v1alpha2.AssistConfig value) {
      copyOnWrite();
      instance.setConfig(value);
      return this;
    }
    /**
     * <pre>
     * The `config` message provides information to the recognizer that
     * specifies how to process the request.
     * The first `AssistRequest` message must contain a `config` message.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
     */
    public Builder setConfig(
        com.google.assistant.embedded.v1alpha2.AssistConfig.Builder builderForValue) {
      copyOnWrite();
      instance.setConfig(builderForValue);
      return this;
    }
    /**
     * <pre>
     * The `config` message provides information to the recognizer that
     * specifies how to process the request.
     * The first `AssistRequest` message must contain a `config` message.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
     */
    public Builder mergeConfig(com.google.assistant.embedded.v1alpha2.AssistConfig value) {
      copyOnWrite();
      instance.mergeConfig(value);
      return this;
    }
    /**
     * <pre>
     * The `config` message provides information to the recognizer that
     * specifies how to process the request.
     * The first `AssistRequest` message must contain a `config` message.
     * </pre>
     *
     * <code>optional .google.assistant.embedded.v1alpha2.AssistConfig config = 1;</code>
     */
    public Builder clearConfig() {
      copyOnWrite();
      instance.clearConfig();
      return this;
    }

    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `AssistRequest` messages. The first `AssistRequest`
     * message must not contain `audio_in` data and all subsequent
     * `AssistRequest` messages must contain `audio_in` data. The audio bytes
     * must be encoded as specified in `AudioInConfig`.
     * Audio must be sent at approximately real-time (16000 samples per second).
     * An error will be returned if audio is sent significantly faster or
     * slower.
     * If [AssistConfig.audio_in_config][] was not set in the first message,
     * then this field is not used. If it was set, this field is populated with
     * the audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `AssistRequest` messages. If 'AudioInConfig' is provided
     * in the first `AssistRequest` message, all subsequent `AssistRequest`
     * messages must contain `audio_in` data. The audio bytes must be encoded as
     * specified in `AudioInConfig`. Audio must be sent at approximately
     * real-time (16000 samples per second). An error will be returned if audio
     * is sent significantly faster or slower.
     * --)
     * </pre>
     *
     * <code>optional bytes audio_in = 2;</code>
     */
    public com.google.protobuf.ByteString getAudioIn() {
      return instance.getAudioIn();
    }
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `AssistRequest` messages. The first `AssistRequest`
     * message must not contain `audio_in` data and all subsequent
     * `AssistRequest` messages must contain `audio_in` data. The audio bytes
     * must be encoded as specified in `AudioInConfig`.
     * Audio must be sent at approximately real-time (16000 samples per second).
     * An error will be returned if audio is sent significantly faster or
     * slower.
     * If [AssistConfig.audio_in_config][] was not set in the first message,
     * then this field is not used. If it was set, this field is populated with
     * the audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `AssistRequest` messages. If 'AudioInConfig' is provided
     * in the first `AssistRequest` message, all subsequent `AssistRequest`
     * messages must contain `audio_in` data. The audio bytes must be encoded as
     * specified in `AudioInConfig`. Audio must be sent at approximately
     * real-time (16000 samples per second). An error will be returned if audio
     * is sent significantly faster or slower.
     * --)
     * </pre>
     *
     * <code>optional bytes audio_in = 2;</code>
     */
    public Builder setAudioIn(com.google.protobuf.ByteString value) {
      copyOnWrite();
      instance.setAudioIn(value);
      return this;
    }
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `AssistRequest` messages. The first `AssistRequest`
     * message must not contain `audio_in` data and all subsequent
     * `AssistRequest` messages must contain `audio_in` data. The audio bytes
     * must be encoded as specified in `AudioInConfig`.
     * Audio must be sent at approximately real-time (16000 samples per second).
     * An error will be returned if audio is sent significantly faster or
     * slower.
     * If [AssistConfig.audio_in_config][] was not set in the first message,
     * then this field is not used. If it was set, this field is populated with
     * the audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `AssistRequest` messages. If 'AudioInConfig' is provided
     * in the first `AssistRequest` message, all subsequent `AssistRequest`
     * messages must contain `audio_in` data. The audio bytes must be encoded as
     * specified in `AudioInConfig`. Audio must be sent at approximately
     * real-time (16000 samples per second). An error will be returned if audio
     * is sent significantly faster or slower.
     * --)
     * </pre>
     *
     * <code>optional bytes audio_in = 2;</code>
     */
    public Builder clearAudioIn() {
      copyOnWrite();
      instance.clearAudioIn();
      return this;
    }

    // @@protoc_insertion_point(builder_scope:google.assistant.embedded.v1alpha2.AssistRequest)
  }
  protected final Object dynamicMethod(
      com.google.protobuf.GeneratedMessageLite.MethodToInvoke method,
      Object arg0, Object arg1) {
    switch (method) {
      case NEW_MUTABLE_INSTANCE: {
        return new com.google.assistant.embedded.v1alpha2.AssistRequest();
      }
      case IS_INITIALIZED: {
        return DEFAULT_INSTANCE;
      }
      case MAKE_IMMUTABLE: {
        return null;
      }
      case NEW_BUILDER: {
        return new Builder();
      }
      case VISIT: {
        Visitor visitor = (Visitor) arg0;
        com.google.assistant.embedded.v1alpha2.AssistRequest other = (com.google.assistant.embedded.v1alpha2.AssistRequest) arg1;
        switch (other.getTypeCase()) {
          case CONFIG: {
            type_ = visitor.visitOneofMessage(
                typeCase_ == 1,
                type_,
                other.type_);
            break;
          }
          case AUDIO_IN: {
            type_ = visitor.visitOneofByteString(
                typeCase_ == 2, type_, other.type_);
            break;
          }
          case TYPE_NOT_SET: {
            visitor.visitOneofNotSet(typeCase_ != 0);
            break;
          }
        }
        if (visitor == com.google.protobuf.GeneratedMessageLite.MergeFromVisitor
            .INSTANCE) {
          if (other.typeCase_ != 0) {
            typeCase_ = other.typeCase_;
          }
        }
        return this;
      }
      case MERGE_FROM_STREAM: {
        com.google.protobuf.CodedInputStream input =
            (com.google.protobuf.CodedInputStream) arg0;
        com.google.protobuf.ExtensionRegistryLite extensionRegistry =
            (com.google.protobuf.ExtensionRegistryLite) arg1;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                com.google.assistant.embedded.v1alpha2.AssistConfig.Builder subBuilder = null;
                if (typeCase_ == 1) {
                  subBuilder = ((com.google.assistant.embedded.v1alpha2.AssistConfig) type_).toBuilder();
                }
                type_ =
                     input.readMessage(com.google.assistant.embedded.v1alpha2.AssistConfig.parser(), extensionRegistry);
                if (subBuilder != null) {
                  subBuilder.mergeFrom((com.google.assistant.embedded.v1alpha2.AssistConfig) type_);
                  type_ = subBuilder.buildPartial();
                }
                typeCase_ = 1;
                break;
              }
              case 18: {
                typeCase_ = 2;
                type_ = input.readBytes();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw new RuntimeException(e.setUnfinishedMessage(this));
        } catch (java.io.IOException e) {
          throw new RuntimeException(
              new com.google.protobuf.InvalidProtocolBufferException(
                  e.getMessage()).setUnfinishedMessage(this));
        } finally {
        }
      }
      case GET_DEFAULT_INSTANCE: {
        return DEFAULT_INSTANCE;
      }
      case GET_PARSER: {
        if (PARSER == null) {    synchronized (com.google.assistant.embedded.v1alpha2.AssistRequest.class) {
            if (PARSER == null) {
              PARSER = new DefaultInstanceBasedParser(DEFAULT_INSTANCE);
            }
          }
        }
        return PARSER;
      }
    }
    throw new UnsupportedOperationException();
  }


  // @@protoc_insertion_point(class_scope:google.assistant.embedded.v1alpha2.AssistRequest)
  private static final com.google.assistant.embedded.v1alpha2.AssistRequest DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new AssistRequest();
    DEFAULT_INSTANCE.makeImmutable();
  }

  public static com.google.assistant.embedded.v1alpha2.AssistRequest getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static volatile com.google.protobuf.Parser<AssistRequest> PARSER;

  public static com.google.protobuf.Parser<AssistRequest> parser() {
    return DEFAULT_INSTANCE.getParserForType();
  }
}

